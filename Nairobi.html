<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Combined Video Recorder</title>
  <style>
    body {
      margin: 0;
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background-color: white;
      color: #333;
      font-size: 18px;
    }

    header {
      background-color: #d63384;
      color: white;
      padding: 30px 20px;
      text-align: center;
      font-size: 36px;
      letter-spacing: 1px;
    }

    .container {
      max-width: 900px;
      margin: 60px auto;
      padding: 40px;
      background-color: #fff;
      border-radius: 10px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
      text-align: center;
    }

    canvas {
      width: 100%;
      max-height: 600px;
      border-radius: 10px;
      background-color: #000;
      margin-bottom: 20px;
    }

    .btn-group {
      display: flex;
      justify-content: center;
      gap: 20px;
      flex-wrap: wrap;
    }

    button {
      padding: 15px 25px;
      background-color: #d63384;
      color: white;
      border: none;
      border-radius: 6px;
      font-size: 18px;
      cursor: pointer;
      transition: background-color 0.3s ease;
    }

    button:hover {
      background-color: #bf2a72;
    }

    @media (max-width: 600px) {
      header {
        font-size: 28px;
        padding: 20px 10px;
      }

      button {
        font-size: 16px;
        padding: 12px 20px;
      }
    }
  </style>
</head>
<body>
  <header>Combined Video Recorder</header>
  <div class="container">
    <canvas id="previewCanvas" width="1280" height="720"></canvas>

    <div class="btn-group">
      <button id="startBtn">Start Recording</button>
      <button id="stopBtn">Stop & Download</button>
    </div>
  </div>

  <script>
    const canvas = document.getElementById('previewCanvas');
    const ctx = canvas.getContext('2d');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');

    let screenStream, cameraStream;
    let screenVideo, cameraVideo;
    let recorder;
    let chunks = [];
    let drawInterval;

    async function setupStreams() {
      try {
        screenStream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: true });
        cameraStream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: true });

        screenVideo = document.createElement('video');
        cameraVideo = document.createElement('video');

        screenVideo.srcObject = screenStream;
        cameraVideo.srcObject = cameraStream;

        screenVideo.play();
        cameraVideo.play();

        // Start drawing screen + camera to canvas
        drawInterval = requestAnimationFrame(drawToCanvas);
      } catch (err) {
        alert('Error: ' + err.message);
        console.error(err);
      }
    }

    function drawToCanvas() {
      if (screenVideo.readyState >= 2) {
        ctx.drawImage(screenVideo, 0, 0, canvas.width, canvas.height);
      }
      if (cameraVideo.readyState >= 2) {
        const camWidth = 320;
        const camHeight = 180;
        ctx.drawImage(cameraVideo, canvas.width - camWidth - 20, canvas.height - camHeight - 20, camWidth, camHeight);
      }
      drawInterval = requestAnimationFrame(drawToCanvas);
    }

    startBtn.onclick = async () => {
      await setupStreams();

      const combinedStream = canvas.captureStream(30); // 30 FPS

      // Merge audio from screen + camera
      const audioContext = new AudioContext();
      const destination = audioContext.createMediaStreamDestination();

      if (screenStream.getAudioTracks().length > 0) {
        const screenAudio = audioContext.createMediaStreamSource(screenStream);
        screenAudio.connect(destination);
      }

      if (cameraStream.getAudioTracks().length > 0) {
        const micAudio = audioContext.createMediaStreamSource(cameraStream);
        micAudio.connect(destination);
      }

      destination.stream.getAudioTracks().forEach(track => {
        combinedStream.addTrack(track);
      });

      recorder = new MediaRecorder(combinedStream);
      chunks = [];

      recorder.ondataavailable = e => {
        if (e.data.size > 0) chunks.push(e.data);
      };

      recorder.onstop = () => {
        cancelAnimationFrame(drawInterval);
        const blob = new Blob(chunks, { type: 'video/webm' });
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = 'combined_recording.webm';
        a.click();
      };

      recorder.start();
      console.log('Recording started');
    };

    stopBtn.onclick = () => {
      if (recorder && recorder.state === 'recording') {
        recorder.stop();
        screenStream.getTracks().forEach(track => track.stop());
        cameraStream.getTracks().forEach(track => track.stop());
        console.log('Recording stopped');
      }
    };
  </script>
</body>
</html>